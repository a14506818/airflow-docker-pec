import pandas as pd
import pyodbc
import time
import traceback
from concurrent.futures import ThreadPoolExecutor, as_completed
import uuid

from src.supplier_assessment_tasks.mol_crawler import MOLCrawler
from src.supplier_assessment_tasks.env_crawler import ENVCrawler

from src.common.common import get_mssql_conn_str

def del_tmp_table():
    """
    åˆªé™¤æš«å­˜è³‡æ–™è¡¨
    """
    conn_str = get_mssql_conn_str()
    conn = pyodbc.connect(conn_str, timeout=5)
    print("âœ… MSSQL é€£ç·šæˆåŠŸ")

    cursor = conn.cursor()
    cursor.execute("DELETE FROM TMP_MOL_compliance_result;")
    print("SQL: DELETE FROM TMP_MOL_compliance_result;")
    cursor.execute("DELETE FROM TMP_ENV_compliance_result;")
    print("SQL: DELETE FROM TMP_ENV_compliance_result;")
    conn.commit()
    print("âœ… åˆªé™¤æš«å­˜è³‡æ–™è¡¨æˆåŠŸ")

    cursor.close()
    conn.close()


def get_partner_list():
    """
    å–å¾— REF ä¾›æ‡‰å•†è©•ä¼°ä»»å‹™çš„çˆ¬èŸ²æ¸…å–®
    """
    # è¼‰å…¥DBé€£ç·š -------------------------------------------------------------------------------------------
    conn_str = get_mssql_conn_str()
    conn = pyodbc.connect(conn_str, timeout=5)
    print("âœ… MSSQL é€£ç·šæˆåŠŸ")

    # å¯«å…¥è³‡æ–™åº«
    cursor = conn.cursor()

    cursor.execute("SELECT partner_name FROM REF_partner_crawler_list_test") # REF_partner_crawler_list
    rows = cursor.fetchall()
    if not rows:
        raise ValueError("âŒ REF_partner_crawler_list è³‡æ–™è¡¨ç‚ºç©ºï¼Œè«‹æª¢æŸ¥è³‡æ–™åº«")

    # æŠŠ tuple æ‹†é–‹
    company_names = [str(r[0]).strip() for r in rows if r[0]]
    company_names = list(set(company_names))  # å»é‡è¤‡ï¼Œéå¿…è¦ä½†å»ºè­°

    print("âœ… å–å¾—å…¬å¸åç¨±æ¸…å–®æˆåŠŸ:", company_names)

    cursor.close()
    conn.close()

    return company_names

def crawl_compliance_data(**context):
    """
    loopä¾›æ‡‰å•†ï¼Œç”¢ç”ŸJOBï¼ŒåŸ·è¡Œçˆ¬èŸ²ï¼Œå¯«å…¥TMP
    """
    def with_retry(func, args=(), job_id='', kwargs=None, max_retries=10, wait_sec=1):
        if kwargs is None:
            kwargs = {}
        for attempt in range(1, max_retries + 1):
            try:
                return func(*args, **kwargs)
            except Exception as e:
                print(f"âŒ ç¬¬ {attempt} æ¬¡å¤±æ•—: {e}")
                update_job_status(job_id, status="fail", error_msg=str(e))
                if attempt == max_retries:
                    raise
                print("ğŸ” é‡è©¦ä¸­...\n")
                time.sleep(wait_sec)

    def crawl_mol(name):
        mol_crawler = MOLCrawler(driver_path)
        return mol_crawler.crawl(name)

    def crawl_env(name):
        env_crawler = ENVCrawler(driver_path)
        return env_crawler.crawl(name)

    def insert_job(job: dict):
        conn_str = get_mssql_conn_str()
        conn = pyodbc.connect(conn_str, timeout=5)
        print("âœ… MSSQL é€£ç·šæˆåŠŸ")

        # å¯«å…¥è³‡æ–™åº«
        cursor = conn.cursor()

        cursor.execute("""
            insert into JOB_compliance_crawler (id, run_key, supplier_name, source_type, status)
            values (?, ?, ?, ?, ?)
        """, 
        job['id'], job['run_key'], job['supplier_name'], job['source_type'], 'pending')

        conn.commit()
        print("âœ… å¯«å…¥ BPM æˆåŠŸ")

        conn.close()

    def insert_tmp_result(df: pd.DataFrame, source:str):
        """å°‡æŸ¥è©¢çµæœå¯«å…¥ TMP__compliance_result"""
        table_name = f"TMP_{source}_compliance_result"
        if df.empty:
            print("âš ï¸ å‚³å…¥ç©ºçš„ DataFrameï¼ŒæœªåŸ·è¡Œå¯«å…¥ã€‚")
            return

        MOL_COLUMNS_MAPPING = {
            "æŸ¥è©¢åç¨±": "search_name",
            "æ³•å¾‹é¡åˆ¥": "law_type",
            "åºè™Ÿ": "seq",
            "ç¸£å¸‚/å–®ä½åˆ¥": "country",
            "å…¬å‘Šæ—¥æœŸ": "announce_date",
            "è™•åˆ†æ—¥æœŸ": "penalty_date",
            "è™•åˆ†å­—è™Ÿ": "penalty_no",
            "äº‹æ¥­å–®ä½åç¨±(è² è²¬äºº)è‡ªç„¶äººå§“å": "partner_name",
            "é•æ³•æ³•è¦æ³•æ¢": "law",
            "é•åæ³•è¦å…§å®¹": "content",
            "å‚™è¨»èªªæ˜": "remark",
            "ç½°é°é‡‘é¡": "fine"  # ä¾‹å¦‚å¾Œè™•ç†ç”¢å‡ºçš„æ¬„ä½å
        }
        ENV_COLUMNS_MAPPING = {
            "çµ±ä¸€ç·¨è™Ÿ": "partner",
            "ä¾›æ‡‰å•†åç¨±": "partner_name",
            "è£ç½°æ—¥": "penalty_date",
            "é•è¦æ—¥": "violation_date",
            "ç¸£å¸‚": "country",
            "è£ç½°å…§å®¹": "description",
            "è¨´é¡˜ç‹€æ…‹": "status",
            "é™æ”¹æ—¥æœŸ-æ”¹å–„å®Œå¦¥": "refine",
            "è£ç½°é‡‘é¡": "fine_amount",
            "è£ç½°å‚™è¨»": "fine_description"  # ä¾‹å¦‚å¾Œè™•ç†ç”¢å‡ºçš„æ¬„ä½å
        }
        #  source : MOL or ENV
        if source == "MOL":
            COLUMNS_MAPPING = MOL_COLUMNS_MAPPING
        elif source == "ENV":
            COLUMNS_MAPPING = ENV_COLUMNS_MAPPING
        else:
            raise ValueError("Invalid source type. Expected 'MOL' or 'ENV'.")
        # æ¬„ä½è½‰æ›
        df = df.rename(columns=COLUMNS_MAPPING)
        # åªä¿ç•™ COLUMNS_MAPPING å®šç¾©çš„æ¬„ä½
        keep_cols = list(COLUMNS_MAPPING.values())  # å– rename å¾Œçš„æ–°æ¬„ä½å
        df = df[keep_cols]
        # å°‡æ‰€æœ‰æ¬„ä½çš„å€¼è½‰ç‚ºå­—ä¸²
        df = df.astype(str)

        # å°‡ DataFrame å¯«å…¥ SQL Server
        conn_str = get_mssql_conn_str()
        conn = pyodbc.connect(conn_str, timeout=5)
        print("âœ… MSSQL é€£ç·šæˆåŠŸ")
        
        # å¯«å…¥è³‡æ–™åº«
        cursor = conn.cursor()

        # å¯«å…¥æ–°è³‡æ–™
        for index, row in df.iterrows():
            print(f"SQL: INSERT INTO {table_name} ({', '.join(row.index)}) VALUES ({', '.join(['?' for _ in row])})")   
            cursor.execute(f"""
                INSERT INTO {table_name} ({', '.join(row.index)})
                VALUES ({', '.join(['?' for _ in row])})
            """, tuple(row))
            
            
        conn.commit()

        conn.close()
        print(f"âœ… å¯«å…¥ {len(df)} ç­†è‡³ {table_name}")    

    def update_job_status(job_id: str, status: str, error_msg: str = None):
        conn_str = get_mssql_conn_str()
        conn = pyodbc.connect(conn_str, timeout=5)
        print("âœ… MSSQL é€£ç·šæˆåŠŸ")

        # å¯«å…¥è³‡æ–™åº«
        cursor = conn.cursor()

        cursor.execute("""
            UPDATE JOB_compliance_crawler
            SET status = ?, error_msg = ?
            WHERE id = ?
        """, status, error_msg, job_id)

        conn.commit()
        print("âœ… å¯«å…¥ BPM æˆåŠŸ")

        conn.close()
    # get XCOM -----------------------------------------------------------------------------------------------
    ti = context["ti"] # å–å¾— Task Instance
    company_names = ti.xcom_pull(task_ids="get_partner_list")
    if not company_names:
        raise ValueError("âŒ å–å¾—å…¬å¸åç¨±æ¸…å–®ç‚ºç©ºï¼Œè«‹æª¢æŸ¥ä¸Šæ¸¸ä»»å‹™")
    print("âœ… æˆåŠŸå–å¾—å…¬å¸åç¨±æ¸…å–®ï¼Œå‰å¹¾ç­†è³‡æ–™å¦‚ä¸‹ï¼š")
    print(company_names[:10])

    # init ---------------------------------------------------------------------------------------------------
    driver_path = "" # not needed, use ChromeDriverManager
    mol_results = []
    env_results = []
    error_logs = []
    run_key = "RK_" + time.strftime("%Y%m%d%H%M%S")

    # ä¸¦è¡ŒæŸ¥è©¢ MOL èˆ‡ ENV -------------------------------------------------------------------------------------
    with ThreadPoolExecutor(max_workers=4) as executor:
        future_to_info = {}
        job_ids = {} # ç´€éŒ„ JOB ID å°æ‡‰çš„å…¬å¸åç¨±èˆ‡ä¾†æº
        for name in company_names:
            # ç”¢ç”ŸJOB
            for source in ['MOL', 'ENV']:
                job_id = str(uuid.uuid4())
                job_data = {
                    "id": job_id,
                    "run_key": run_key,
                    "supplier_name": name,
                    "source_type": source
                }
                insert_job(job_data) 
                job_ids[(name, source)] = job_id
            # åŸ·è¡Œçˆ¬èŸ²
            future_to_info[executor.submit(with_retry, crawl_mol, args=(name,), job_id=job_ids[(name, 'MOL')])] = (name, 'MOL')
            future_to_info[executor.submit(with_retry, crawl_env, args=(name,), job_id=job_ids[(name, 'ENV')])] = (name, 'ENV')

        for future in as_completed(future_to_info):
            name, source = future_to_info[future]
            job_id = job_ids[(name, source)]
            try:
                result = future.result()
                if not result.empty:
                    if source == 'MOL':
                        mol_results.append(result)
                        result["run_key"] = run_key
                        result["job_id"] = job_ids[(name, source)]
                        insert_tmp_result(result,'MOL')
                    elif source == 'ENV':
                        env_results.append(result)
                        result["run_key"] = run_key
                        result["job_id"] = job_ids[(name, source)]
                        insert_tmp_result(result,'ENV')
                update_job_status(job_id, status="success", error_msg='')
            except Exception as e:
                err = f"{source} æŸ¥è©¢ {name} ç™¼ç”ŸéŒ¯èª¤: {e}"
                print("âŒ ",err)
                error_logs.append(err + '\n' + traceback.format_exc())
                update_job_status(job_id, status="fail", error_msg=str(e))